{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.utils import shuffle\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, \\\n",
    "                            r2_score, mean_poisson_deviance, mean_gamma_deviance, accuracy_score \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>15201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15599.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>17429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>17527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>16799.185547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>16353.365234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>16618.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>16884.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>16447.378906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Close\n",
       "1203 2018-01-02  14982.099609\n",
       "1204 2018-01-03  15201.000000\n",
       "1205 2018-01-04  15599.200195\n",
       "1206 2018-01-05  17429.500000\n",
       "1207 2018-01-06  17527.000000\n",
       "...         ...           ...\n",
       "2978 2022-11-12  16799.185547\n",
       "2979 2022-11-13  16353.365234\n",
       "2980 2022-11-14  16618.199219\n",
       "2981 2022-11-15  16884.613281\n",
       "2982 2022-11-16  16447.378906\n",
       "\n",
       "[1780 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc = pd.read_csv('BTC.csv')\n",
    "df_btc['Date'] = pd.to_datetime(df_btc['Date'])\n",
    "df_btc = df_btc[['Date','Close']]\n",
    "df_btc = df_btc[df_btc['Date'] > '2018-01-01']\n",
    "df_btc = df_btc.dropna()\n",
    "btc_stock = df_btc.copy()\n",
    "btc_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_btc['Date']\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_btc = scaler.fit_transform(np.array(df_btc).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test split\n",
    "training_size = int(len(df_btc)*0.8)\n",
    "test_size = len(df_btc) - training_size\n",
    "\n",
    "train_data, test_data = df_btc[0:training_size,:], df_btc[training_size:len(df_btc),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1408, 15)\n",
      "y_train:  (1408,)\n",
      "X_test:  (340, 15)\n"
     ]
    }
   ],
   "source": [
    "time_step = 15\n",
    "X_train_wof, y_train_wof = create_dataset(train_data, time_step)\n",
    "X_test_wof, y_test_wof = create_dataset(test_data, time_step)\n",
    "\n",
    "print(\"X_train: \", X_train_wof.shape)\n",
    "print(\"y_train: \", y_train_wof.shape)\n",
    "print(\"X_test: \", X_test_wof.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1408, 15, 1)\n",
      "X_test:  (340, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_wof = X_train_wof.reshape(X_train_wof.shape[0],X_train_wof.shape[1] , 1)\n",
    "X_test_wof = X_test_wof.reshape(X_test_wof.shape[0],X_test_wof.shape[1] , 1)\n",
    "\n",
    "print(\"X_train: \", X_train_wof.shape)\n",
    "print(\"X_test: \", X_test_wof.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 0.0229 - val_loss: 0.0097\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0041\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 9.2135e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 9.2197e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.4478e-04 - val_loss: 9.3182e-04\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.1840e-04 - val_loss: 9.4601e-04\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.0720e-04 - val_loss: 9.5034e-04\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.0422e-04 - val_loss: 9.5770e-04\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 9.0137e-04 - val_loss: 9.4613e-04\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.9891e-04 - val_loss: 9.7313e-04\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.9660e-04 - val_loss: 9.7114e-04\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.9253e-04 - val_loss: 0.0010\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.9217e-04 - val_loss: 9.7012e-04\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.8837e-04 - val_loss: 9.5557e-04\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.8701e-04 - val_loss: 9.9999e-04\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.8344e-04 - val_loss: 9.5823e-04\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.8208e-04 - val_loss: 9.8215e-04\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7644e-04 - val_loss: 9.5197e-04\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7785e-04 - val_loss: 9.6142e-04\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7775e-04 - val_loss: 0.0010\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7736e-04 - val_loss: 9.8501e-04\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7408e-04 - val_loss: 9.6395e-04\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7349e-04 - val_loss: 9.5635e-04\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6883e-04 - val_loss: 0.0010\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.7205e-04 - val_loss: 9.9879e-04\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6800e-04 - val_loss: 9.9610e-04\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6668e-04 - val_loss: 9.4898e-04\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6531e-04 - val_loss: 9.5615e-04\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6235e-04 - val_loss: 9.6290e-04\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6133e-04 - val_loss: 9.7199e-04\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.6003e-04 - val_loss: 9.8139e-04\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5899e-04 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5924e-04 - val_loss: 9.5646e-04\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5940e-04 - val_loss: 0.0010\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5747e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5575e-04 - val_loss: 9.6554e-04\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5507e-04 - val_loss: 9.9837e-04\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5485e-04 - val_loss: 9.7751e-04\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4890e-04 - val_loss: 0.0010\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4904e-04 - val_loss: 9.5389e-04\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.5163e-04 - val_loss: 9.7164e-04\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4781e-04 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4944e-04 - val_loss: 9.4998e-04\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4801e-04 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4478e-04 - val_loss: 9.6668e-04\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4510e-04 - val_loss: 9.8344e-04\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4392e-04 - val_loss: 9.6708e-04\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4244e-04 - val_loss: 9.9885e-04\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4145e-04 - val_loss: 9.8972e-04\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4064e-04 - val_loss: 0.0010\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.4294e-04 - val_loss: 9.9675e-04\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3717e-04 - val_loss: 9.4658e-04\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3758e-04 - val_loss: 0.0010\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3799e-04 - val_loss: 9.7945e-04\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3510e-04 - val_loss: 0.0010\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3408e-04 - val_loss: 0.0011\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3743e-04 - val_loss: 9.9099e-04\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2989e-04 - val_loss: 9.3555e-04\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3235e-04 - val_loss: 0.0010\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2695e-04 - val_loss: 9.7077e-04\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3090e-04 - val_loss: 0.0010\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.3163e-04 - val_loss: 9.5666e-04\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2757e-04 - val_loss: 9.4878e-04\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2771e-04 - val_loss: 0.0010\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2593e-04 - val_loss: 0.0010\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2731e-04 - val_loss: 9.7916e-04\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2665e-04 - val_loss: 9.7592e-04\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2410e-04 - val_loss: 9.9706e-04\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2391e-04 - val_loss: 9.9794e-04\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2238e-04 - val_loss: 9.6906e-04\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1995e-04 - val_loss: 9.5496e-04\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.2216e-04 - val_loss: 9.7194e-04\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1860e-04 - val_loss: 0.0010\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1886e-04 - val_loss: 9.8767e-04\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1691e-04 - val_loss: 0.0010\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1731e-04 - val_loss: 9.8561e-04\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1502e-04 - val_loss: 9.6183e-04\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1608e-04 - val_loss: 9.9243e-04\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1449e-04 - val_loss: 9.8555e-04\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1508e-04 - val_loss: 0.0010\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1360e-04 - val_loss: 9.8672e-04\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1171e-04 - val_loss: 9.7343e-04\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1125e-04 - val_loss: 0.0010\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0959e-04 - val_loss: 9.9492e-04\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0721e-04 - val_loss: 0.0010\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0929e-04 - val_loss: 9.8249e-04\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0848e-04 - val_loss: 9.7559e-04\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0734e-04 - val_loss: 9.9755e-04\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0775e-04 - val_loss: 9.9640e-04\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0724e-04 - val_loss: 0.0010\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0532e-04 - val_loss: 9.8826e-04\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0274e-04 - val_loss: 9.7774e-04\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0356e-04 - val_loss: 9.5498e-04\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0277e-04 - val_loss: 0.0010\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0168e-04 - val_loss: 0.0010\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0196e-04 - val_loss: 9.7506e-04\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9980e-04 - val_loss: 9.8901e-04\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9690e-04 - val_loss: 0.0011\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.0106e-04 - val_loss: 9.7583e-04\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9552e-04 - val_loss: 9.4467e-04\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9902e-04 - val_loss: 9.9608e-04\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9787e-04 - val_loss: 9.8888e-04\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9894e-04 - val_loss: 0.0010\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9654e-04 - val_loss: 0.0010\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9340e-04 - val_loss: 0.0010\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9375e-04 - val_loss: 9.7803e-04\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9391e-04 - val_loss: 0.0010\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9356e-04 - val_loss: 0.0010\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9053e-04 - val_loss: 9.7970e-04\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9091e-04 - val_loss: 9.7741e-04\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9032e-04 - val_loss: 9.5907e-04\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9018e-04 - val_loss: 0.0010\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8810e-04 - val_loss: 9.8170e-04\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.9130e-04 - val_loss: 9.8697e-04\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8736e-04 - val_loss: 9.9470e-04\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8722e-04 - val_loss: 9.9155e-04\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8419e-04 - val_loss: 0.0010\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8801e-04 - val_loss: 9.9584e-04\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8444e-04 - val_loss: 9.6791e-04\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8351e-04 - val_loss: 9.8773e-04\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8297e-04 - val_loss: 9.9859e-04\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8282e-04 - val_loss: 0.0010\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8082e-04 - val_loss: 0.0010\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8042e-04 - val_loss: 0.0010\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8002e-04 - val_loss: 9.6464e-04\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.8005e-04 - val_loss: 9.8165e-04\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7848e-04 - val_loss: 9.6428e-04\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7735e-04 - val_loss: 9.7709e-04\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7655e-04 - val_loss: 9.6390e-04\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7669e-04 - val_loss: 9.7972e-04\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7777e-04 - val_loss: 0.0010\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7604e-04 - val_loss: 0.0010\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7744e-04 - val_loss: 0.0010\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.7472e-04 - val_loss: 0.0010\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.7258e-04 - val_loss: 0.0010\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7258e-04 - val_loss: 0.0011\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7370e-04 - val_loss: 9.9981e-04\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.7207e-04 - val_loss: 0.0010\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6959e-04 - val_loss: 0.0010\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.7072e-04 - val_loss: 9.6904e-04\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.6766e-04 - val_loss: 9.5906e-04\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6882e-04 - val_loss: 9.6523e-04\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.6838e-04 - val_loss: 0.0010\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6579e-04 - val_loss: 0.0010\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6902e-04 - val_loss: 0.0010\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6723e-04 - val_loss: 9.7245e-04\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6566e-04 - val_loss: 9.6936e-04\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6720e-04 - val_loss: 9.8415e-04\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6493e-04 - val_loss: 9.8186e-04\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6341e-04 - val_loss: 0.0010\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6463e-04 - val_loss: 0.0010\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6338e-04 - val_loss: 9.7047e-04\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6397e-04 - val_loss: 9.6724e-04\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6473e-04 - val_loss: 0.0010\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6067e-04 - val_loss: 9.5284e-04\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6043e-04 - val_loss: 9.5363e-04\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5800e-04 - val_loss: 9.9387e-04\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5942e-04 - val_loss: 0.0010\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6080e-04 - val_loss: 0.0010\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5718e-04 - val_loss: 9.4811e-04\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.6061e-04 - val_loss: 0.0010\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5657e-04 - val_loss: 0.0010\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5549e-04 - val_loss: 0.0011\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5668e-04 - val_loss: 9.8656e-04\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5184e-04 - val_loss: 9.2265e-04\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5512e-04 - val_loss: 0.0011\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5341e-04 - val_loss: 9.7484e-04\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5137e-04 - val_loss: 9.4537e-04\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5321e-04 - val_loss: 9.7054e-04\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5267e-04 - val_loss: 0.0010\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5091e-04 - val_loss: 0.0010\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5105e-04 - val_loss: 0.0010\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.5043e-04 - val_loss: 0.0010\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.4904e-04 - val_loss: 9.8868e-04\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.4835e-04 - val_loss: 0.0010\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 7.4735e-04 - val_loss: 9.5427e-04\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4867e-04 - val_loss: 9.6136e-04\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4758e-04 - val_loss: 0.0010\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4716e-04 - val_loss: 0.0010\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4509e-04 - val_loss: 0.0010\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4508e-04 - val_loss: 9.7339e-04\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4492e-04 - val_loss: 0.0011\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4495e-04 - val_loss: 0.0010\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4460e-04 - val_loss: 9.7837e-04\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4502e-04 - val_loss: 9.9644e-04\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4169e-04 - val_loss: 9.5564e-04\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4218e-04 - val_loss: 9.9806e-04\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3993e-04 - val_loss: 9.6966e-04\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.4175e-04 - val_loss: 9.8784e-04\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3972e-04 - val_loss: 0.0011\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3957e-04 - val_loss: 9.7200e-04\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3918e-04 - val_loss: 0.0010\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3919e-04 - val_loss: 0.0010\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3841e-04 - val_loss: 0.0010\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3743e-04 - val_loss: 0.0011\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3927e-04 - val_loss: 9.8878e-04\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.3708e-04 - val_loss: 0.0010\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0010326491901651025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wof=Sequential()\n",
    "model_wof.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
    "model_wof.add(Dense(1))\n",
    "model_wof.compile(loss=\"mean_squared_error\",optimizer=\"sgd\")\n",
    "history = model_wof.fit(\n",
    "                    X_train_wof,\n",
    "                    y_train_wof,\n",
    "                    validation_data=(X_test_wof,y_test_wof),\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    verbose=1\n",
    "                    )\n",
    "model_wof.evaluate(X_test_wof, y_test_wof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13625.000000</td>\n",
       "      <td>15444.599609</td>\n",
       "      <td>13163.599609</td>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14978.200195</td>\n",
       "      <td>15572.799805</td>\n",
       "      <td>14844.500000</td>\n",
       "      <td>15201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15270.700195</td>\n",
       "      <td>15739.700195</td>\n",
       "      <td>14522.200195</td>\n",
       "      <td>15599.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15477.200195</td>\n",
       "      <td>17705.199219</td>\n",
       "      <td>15202.799805</td>\n",
       "      <td>17429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>17462.099609</td>\n",
       "      <td>17712.400391</td>\n",
       "      <td>16764.599609</td>\n",
       "      <td>17527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>17036.875000</td>\n",
       "      <td>17066.675781</td>\n",
       "      <td>16651.775391</td>\n",
       "      <td>16799.185547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>16799.722656</td>\n",
       "      <td>16920.765625</td>\n",
       "      <td>16320.634766</td>\n",
       "      <td>16353.365234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>16352.028320</td>\n",
       "      <td>17109.324219</td>\n",
       "      <td>15872.941406</td>\n",
       "      <td>16618.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>16617.484375</td>\n",
       "      <td>17051.962891</td>\n",
       "      <td>16542.550781</td>\n",
       "      <td>16884.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>16900.273438</td>\n",
       "      <td>16960.294922</td>\n",
       "      <td>16447.378906</td>\n",
       "      <td>16447.378906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close\n",
       "1203 2018-01-02  13625.000000  15444.599609  13163.599609  14982.099609\n",
       "1204 2018-01-03  14978.200195  15572.799805  14844.500000  15201.000000\n",
       "1205 2018-01-04  15270.700195  15739.700195  14522.200195  15599.200195\n",
       "1206 2018-01-05  15477.200195  17705.199219  15202.799805  17429.500000\n",
       "1207 2018-01-06  17462.099609  17712.400391  16764.599609  17527.000000\n",
       "...         ...           ...           ...           ...           ...\n",
       "2978 2022-11-12  17036.875000  17066.675781  16651.775391  16799.185547\n",
       "2979 2022-11-13  16799.722656  16920.765625  16320.634766  16353.365234\n",
       "2980 2022-11-14  16352.028320  17109.324219  15872.941406  16618.199219\n",
       "2981 2022-11-15  16617.484375  17051.962891  16542.550781  16884.613281\n",
       "2982 2022-11-16  16900.273438  16960.294922  16447.378906  16447.378906\n",
       "\n",
       "[1780 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc = pd.read_csv('BTC.csv')\n",
    "df_btc['Date'] = pd.to_datetime(df_btc['Date'])\n",
    "df_btc = df_btc[['Date','Open','High','Low','Close']]\n",
    "df_btc = df_btc[df_btc['Date'] > '2018-01-01']\n",
    "df_btc = df_btc.dropna()\n",
    "btc_stock = df_btc.copy()\n",
    "btc_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 4)\n"
     ]
    }
   ],
   "source": [
    "del df_btc['Date']\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_btc = scaler.fit_transform(df_btc)\n",
    "print(df_btc.shape)\n",
    "with open('scaler BTC.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test split\n",
    "training_size = int(len(df_btc)*0.8)\n",
    "test_size = len(df_btc) - training_size\n",
    "\n",
    "train_data, test_data = df_btc[0:training_size,:], df_btc[training_size:len(df_btc),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step,-1])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1408, 15, 4)\n",
      "y_train:  (1408,)\n",
      "X_test:  (340, 15, 4)\n",
      "y_test:  (340,)\n"
     ]
    }
   ],
   "source": [
    "time_step = 15\n",
    "X_train_wf, y_train_wf = create_dataset(train_data, time_step)\n",
    "X_test_wf, y_test_wf = create_dataset(test_data, time_step)\n",
    "\n",
    "print(\"X_train: \", X_train_wf.shape)\n",
    "print(\"y_train: \", y_train_wf.shape)\n",
    "print(\"X_test: \", X_test_wf.shape)\n",
    "print(\"y_test: \", y_test_wf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 8ms/step - loss: 0.0861 - val_loss: 0.0058\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 9.6178e-04 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 8.8518e-04 - val_loss: 9.4571e-04\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.8120e-04 - val_loss: 9.7370e-04\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 7.1526e-04 - val_loss: 9.4839e-04\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.9785e-04 - val_loss: 9.2475e-04\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.7439e-04 - val_loss: 9.4836e-04\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.5410e-04 - val_loss: 0.0010\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.5510e-04 - val_loss: 0.0010\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.0933e-04 - val_loss: 9.0201e-04\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1689e-04 - val_loss: 9.4005e-04\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 6.1217e-04 - val_loss: 8.2474e-04\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9721e-04 - val_loss: 0.0011\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9970e-04 - val_loss: 8.1020e-04\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 6.1750e-04 - val_loss: 8.6000e-04\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.7645e-04 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.5169e-04 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.5472e-04 - val_loss: 0.0011\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4602e-04 - val_loss: 8.6620e-04\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.9013e-04 - val_loss: 8.1535e-04\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4174e-04 - val_loss: 0.0010\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4963e-04 - val_loss: 8.2515e-04\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.4058e-04 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.3230e-04 - val_loss: 9.3731e-04\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2675e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2772e-04 - val_loss: 9.5636e-04\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.2346e-04 - val_loss: 7.7154e-04\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 5.1414e-04 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.0104e-04 - val_loss: 8.3145e-04\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 5.0590e-04 - val_loss: 9.3391e-04\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.9711e-04 - val_loss: 9.1076e-04\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.0080e-04 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.9294e-04 - val_loss: 7.7946e-04\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9657e-04 - val_loss: 9.0924e-04\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 5.1162e-04 - val_loss: 9.0099e-04\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.9479e-04 - val_loss: 9.3450e-04\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.8661e-04 - val_loss: 8.4291e-04\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.7754e-04 - val_loss: 8.1934e-04\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.6761e-04 - val_loss: 0.0011\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.8092e-04 - val_loss: 9.1792e-04\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6521e-04 - val_loss: 7.9548e-04\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.7292e-04 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.6508e-04 - val_loss: 8.5513e-04\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.4480e-04 - val_loss: 7.9849e-04\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5385e-04 - val_loss: 7.4645e-04\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.5037e-04 - val_loss: 9.0060e-04\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4571e-04 - val_loss: 6.7133e-04\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4128e-04 - val_loss: 8.8341e-04\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4587e-04 - val_loss: 7.5783e-04\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.4218e-04 - val_loss: 9.9314e-04\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3270e-04 - val_loss: 7.4291e-04\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3641e-04 - val_loss: 6.5084e-04\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2722e-04 - val_loss: 0.0010\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1965e-04 - val_loss: 7.5745e-04\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.2666e-04 - val_loss: 7.9060e-04\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1356e-04 - val_loss: 9.4265e-04\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.1617e-04 - val_loss: 8.3822e-04\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1595e-04 - val_loss: 7.6869e-04\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0274e-04 - val_loss: 7.2122e-04\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0493e-04 - val_loss: 7.1401e-04\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.1062e-04 - val_loss: 6.2064e-04\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9385e-04 - val_loss: 8.7675e-04\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.9872e-04 - val_loss: 6.3008e-04\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8151e-04 - val_loss: 5.7187e-04\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0804e-04 - val_loss: 6.1299e-04\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0778e-04 - val_loss: 5.6533e-04\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.9052e-04 - val_loss: 7.8630e-04\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.0245e-04 - val_loss: 5.5356e-04\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8551e-04 - val_loss: 6.1103e-04\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7638e-04 - val_loss: 7.2318e-04\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8224e-04 - val_loss: 5.4683e-04\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8057e-04 - val_loss: 6.4833e-04\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.8046e-04 - val_loss: 5.3512e-04\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 4.3904e-04 - val_loss: 9.3618e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6924e-04 - val_loss: 7.1627e-04\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6701e-04 - val_loss: 5.6916e-04\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5863e-04 - val_loss: 5.9119e-04\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5441e-04 - val_loss: 7.0772e-04\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6825e-04 - val_loss: 7.1238e-04\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.7470e-04 - val_loss: 6.1618e-04\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4619e-04 - val_loss: 5.6169e-04\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5328e-04 - val_loss: 5.2644e-04\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.6363e-04 - val_loss: 6.6824e-04\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5149e-04 - val_loss: 6.1349e-04\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5030e-04 - val_loss: 6.9717e-04\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3654e-04 - val_loss: 5.9144e-04\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3904e-04 - val_loss: 6.0213e-04\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.6635e-04 - val_loss: 5.1185e-04\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4604e-04 - val_loss: 6.4813e-04\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5696e-04 - val_loss: 4.9392e-04\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5657e-04 - val_loss: 5.2406e-04\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4464e-04 - val_loss: 6.4356e-04\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3293e-04 - val_loss: 7.5841e-04\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3167e-04 - val_loss: 7.1961e-04\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.5196e-04 - val_loss: 6.9163e-04\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4299e-04 - val_loss: 4.8198e-04\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3631e-04 - val_loss: 5.2837e-04\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4060e-04 - val_loss: 4.8497e-04\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1656e-04 - val_loss: 9.5307e-04\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.2561e-04 - val_loss: 5.4286e-04\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1820e-04 - val_loss: 5.1264e-04\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0771e-04 - val_loss: 4.5155e-04\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2077e-04 - val_loss: 4.4794e-04\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2452e-04 - val_loss: 4.8267e-04\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2689e-04 - val_loss: 6.6857e-04\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.3095e-04 - val_loss: 4.4374e-04\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1921e-04 - val_loss: 5.0217e-04\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1459e-04 - val_loss: 4.4305e-04\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0740e-04 - val_loss: 4.5175e-04\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1029e-04 - val_loss: 7.2212e-04\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2037e-04 - val_loss: 6.5392e-04\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2665e-04 - val_loss: 4.5145e-04\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1782e-04 - val_loss: 4.8195e-04\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1720e-04 - val_loss: 4.2410e-04\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1767e-04 - val_loss: 4.9559e-04\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0264e-04 - val_loss: 4.8430e-04\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1722e-04 - val_loss: 4.9112e-04\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.3508e-04 - val_loss: 4.4545e-04\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.2442e-04 - val_loss: 5.6081e-04\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0561e-04 - val_loss: 4.3687e-04\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9271e-04 - val_loss: 5.9059e-04\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9252e-04 - val_loss: 4.1540e-04\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.1082e-04 - val_loss: 4.1431e-04\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9549e-04 - val_loss: 5.5562e-04\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0192e-04 - val_loss: 4.1154e-04\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.0290e-04 - val_loss: 4.3332e-04\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2693e-04 - val_loss: 4.2089e-04\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8926e-04 - val_loss: 5.2867e-04\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9900e-04 - val_loss: 4.7595e-04\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1744e-04 - val_loss: 4.0661e-04\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9886e-04 - val_loss: 4.2300e-04\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0292e-04 - val_loss: 5.1944e-04\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.2171e-04 - val_loss: 4.4114e-04\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9762e-04 - val_loss: 6.1284e-04\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9376e-04 - val_loss: 7.7711e-04\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0321e-04 - val_loss: 5.9939e-04\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8038e-04 - val_loss: 5.5447e-04\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8884e-04 - val_loss: 4.6785e-04\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8826e-04 - val_loss: 3.9983e-04\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0799e-04 - val_loss: 3.9168e-04\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8430e-04 - val_loss: 4.7662e-04\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9841e-04 - val_loss: 5.0056e-04\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8676e-04 - val_loss: 4.8948e-04\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9579e-04 - val_loss: 3.8737e-04\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9563e-04 - val_loss: 4.9301e-04\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8001e-04 - val_loss: 4.1683e-04\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7796e-04 - val_loss: 4.3819e-04\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9764e-04 - val_loss: 5.5769e-04\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1336e-04 - val_loss: 4.5930e-04\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8172e-04 - val_loss: 5.1634e-04\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7275e-04 - val_loss: 5.4042e-04\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9191e-04 - val_loss: 8.0354e-04\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8823e-04 - val_loss: 3.9279e-04\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9231e-04 - val_loss: 3.8216e-04\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8511e-04 - val_loss: 3.7674e-04\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8330e-04 - val_loss: 4.4214e-04\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.9378e-04 - val_loss: 5.0193e-04\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7423e-04 - val_loss: 4.0401e-04\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6787e-04 - val_loss: 3.7362e-04\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0644e-04 - val_loss: 3.8523e-04\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8083e-04 - val_loss: 5.8510e-04\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1266e-04 - val_loss: 4.4008e-04\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.7833e-04 - val_loss: 4.5882e-04\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7191e-04 - val_loss: 3.7712e-04\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7543e-04 - val_loss: 4.0067e-04\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8678e-04 - val_loss: 3.9737e-04\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.4626e-04 - val_loss: 4.0799e-04\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6892e-04 - val_loss: 3.6658e-04\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7101e-04 - val_loss: 4.9701e-04\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8123e-04 - val_loss: 3.7146e-04\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7611e-04 - val_loss: 4.9274e-04\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7804e-04 - val_loss: 4.0070e-04\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7714e-04 - val_loss: 4.7658e-04\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8308e-04 - val_loss: 4.3154e-04\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.1065e-04 - val_loss: 8.2647e-04\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 3.3765e-04 - val_loss: 4.1386e-04\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.8346e-04 - val_loss: 3.6948e-04\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.7050e-04 - val_loss: 3.6212e-04\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7977e-04 - val_loss: 4.2200e-04\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0666e-04 - val_loss: 4.6728e-04\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8973e-04 - val_loss: 3.7423e-04\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.9865e-04 - val_loss: 3.7259e-04\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8688e-04 - val_loss: 5.7058e-04\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7491e-04 - val_loss: 3.8533e-04\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7128e-04 - val_loss: 4.2933e-04\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6599e-04 - val_loss: 4.7281e-04\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6524e-04 - val_loss: 4.0397e-04\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 3.0281e-04 - val_loss: 3.6072e-04\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6560e-04 - val_loss: 3.6734e-04\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6641e-04 - val_loss: 3.7391e-04\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.8484e-04 - val_loss: 3.6091e-04\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8105e-04 - val_loss: 4.1599e-04\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.6985e-04 - val_loss: 3.7604e-04\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.7489e-04 - val_loss: 3.9202e-04\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 2.6609e-04 - val_loss: 4.0217e-04\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.7356e-04 - val_loss: 4.8402e-04\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 2.8564e-04 - val_loss: 5.9621e-04\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9621e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0005962062859907746"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wf=Sequential()\n",
    "model_wf.add(LSTM(10,input_shape=(None,4),activation=\"relu\"))\n",
    "model_wf.add(Dense(1))\n",
    "model_wf.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\n",
    "history = model_wf.fit(\n",
    "                    X_train_wf,\n",
    "                    y_train_wf,\n",
    "                    validation_data=(X_test_wf,y_test_wf),\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    verbose=1\n",
    "                    )\n",
    "model_wf.evaluate(X_test_wf, y_test_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgU0lEQVR4nO3de3Bc5Znn8e/Trbtsy5IsGxvZWNwxJOFiHLKBLIQl2CTBsCEMZJhhatkyqR1YpiYwMZWEJalULWR3IZuZXIoMniUwCRCybLyFGQgDLLlwM47BNthYBoPlqyzbkmVdW+fZP86R1eqWbNmW1OLN71OlOt3nnO5++nTr12+/5+1zzN0REZFwpQpdgIiIjC0FvYhI4BT0IiKBU9CLiAROQS8iEriiQheQa9q0aT537txClyEi8pHyxhtv7Hb3uqGWTbignzt3LitXrix0GSIiHylm9sFwy9R1IyISOAW9iEjgFPQiIoGbcH30IiJHo7e3l6amJrq6ugpdypgqKyujvr6e4uLiEd9GQS8iQWhqamLy5MnMnTsXMyt0OWPC3WlpaaGpqYmGhoYR305dNyIShK6uLmpra4MNeQAzo7a29oi/tSjoRSQYIYd8v6N5jsEE/Y7WLu57dgObmtsLXYqIyIQSTNDv2t/FD55vZPPuA4UuRUT+BO3bt48f/ehHR3y7K664gn379o1+QVmCCfpU8nUm0nlURKQAhgv6TCZzyNutWLGCqVOnjlFVsWBG3fR3W0U6Y5aIFMDSpUvZtGkTZ599NsXFxZSVlVFdXc369et59913ueqqq9iyZQtdXV3cdtttLFmyBBg47Et7ezuLFi3iwgsv5A9/+APHH388v/71rykvLz/m2oIJ+v4WvU6NKCLf/r/reHtb26je57xZU/gvXzxz2OX33HMPa9euZfXq1bz44ot8/vOfZ+3atQeHQS5btoyamho6Ozs5//zz+dKXvkRtbe2g+9i4cSO/+MUv+OlPf8q1117Lr371K2644YZjrj24oFfXjYhMBAsWLBg01v0HP/gBTz75JABbtmxh48aNeUHf0NDA2WefDcB5553H5s2bR6WWgII+nqrrRkQO1fIeL5WVlQcvv/jiizz33HO8/PLLVFRUcPHFFw85Fr60tPTg5XQ6TWdn56jUEszOWFOLXkQKaPLkyezfv3/IZa2trVRXV1NRUcH69et55ZVXxrW24Fr06qMXkUKora3l05/+NGeddRbl5eXMmDHj4LKFCxfyk5/8hDPOOIPTTjuNCy64YFxrCyjo+1v0CnoRKYyf//znQ84vLS3l6aefHnJZfz/8tGnTWLt27cH5t99++6jVFUzXzcGgjwpciIjIBBNM0GscvYjI0EYU9Ga20Mw2mFmjmS0dYnmpmT2WLH/VzOYm84vN7CEzW2Nm75jZnaNc/0GpVP84+rF6BBGRj6bDBr2ZpYEfAouAecD1ZjYvZ7WbgL3ufjJwP3BvMv/LQKm7fww4D7i5/0NgtGl4pYjI0EbSol8ANLr7e+7eAzwKLM5ZZzHwUHL5CeBSi8c7OlBpZkVAOdADjO7P1RL6wZSIyNBGEvTHA1uyrjcl84Zcx90zQCtQSxz6B4DtwIfAf3f3PbkPYGZLzGylma1sbm4+4icR30c8VYteRGSwsd4ZuwDoA2YBDcDXzOzE3JXc/QF3n+/u8+vq6o7qgXSsGxEppKM9TDHA97//fTo6Oka5ogEjCfqtwOys6/XJvCHXSbppqoAW4CvAv7h7r7vvAn4PzD/WooeirhsRKaSJHPQj+cHU68ApZtZAHOjXEQd4tuXAjcDLwDXA8+7uZvYh8FngYTOrBC4Avj9KtQ+SToK+T0kvIgWQfZjiyy67jOnTp/P444/T3d3N1Vdfzbe//W0OHDjAtddeS1NTE319fXzrW99i586dbNu2jUsuuYRp06bxwgsvjHpthw16d8+Y2S3AM0AaWObu68zsO8BKd18OPEgc5o3AHuIPA4hH6/yTma0DDPgnd39r1J8FYMl3E/XRiwhPL4Uda0b3Po/7GCy6Z9jF2YcpfvbZZ3niiSd47bXXcHeuvPJKXnrpJZqbm5k1axZPPfUUEB8Dp6qqivvuu48XXniBadOmjW7NiREdAsHdVwArcubdlXW5i3goZe7t2oeaPxYG+ujH49FERIb37LPP8uyzz3LOOecA0N7ezsaNG7nooov42te+xte//nW+8IUvcNFFF41LPQEd6yaeqkUvIodqeY8Hd+fOO+/k5ptvzlu2atUqVqxYwTe/+U0uvfRS7rrrriHuYXQFcwgE7YwVkULKPkzx5ZdfzrJly2hvbwdg69at7Nq1i23btlFRUcENN9zAHXfcwapVq/JuOxaCadFrHL2IFFL2YYoXLVrEV77yFT71qU8BMGnSJB555BEaGxu54447SKVSFBcX8+Mf/xiAJUuWsHDhQmbNmlWYnbEfFRpHLyKFlnuY4ttuu23Q9ZNOOonLL78873a33nort95665jVpa4bEZHABRT08VRdNyIigwUT9DpnrIj8KXTdHs1zDCboIW7V/ym80CKSr6ysjJaWlqAzwN1paWmhrKzsiG4XzM5YiPvp1XUj8qepvr6epqYmjvYIuB8VZWVl1NfXH9FtAgz6QlchIoVQXFxMQ0NDocuYkILqujHTzlgRkVxBBX3KTMe6ERHJEVjQQ6S+GxGRQQILevXRi4jkCiro1UcvIpIvqKBPpyzoMbQiIkcjqKBPmdGnoBcRGSSooDf10YuI5Akq6HUIBBGRfIEFvRFFha5CRGRiCSzoNepGRCRXUEGvPnoRkXxBBX0qpT56EZFcYQW9DlMsIpInwKAvdBUiIhNLUEGvQyCIiOQLKuh1mGIRkXyBBb1a9CIiuQILeu2MFRHJFVTQaxy9iEi+oIJex7oREckXWNCrRS8ikiusoE+pj15EJFdYQW+oRS8ikiOwoNepBEVEcgUW9NCnJr2IyCBBBb1pHL2ISJ4RBb2ZLTSzDWbWaGZLh1heamaPJctfNbO5Wcs+bmYvm9k6M1tjZmWjWP8g6qMXEcl32KA3szTwQ2ARMA+43szm5ax2E7DX3U8G7gfuTW5bBDwCfNXdzwQuBnpHrfoc6qMXEck3khb9AqDR3d9z9x7gUWBxzjqLgYeSy08Al5qZAZ8D3nL3NwHcvcXd+0an9HwaRy8ikm8kQX88sCXrelMyb8h13D0DtAK1wKmAm9kzZrbKzP5uqAcwsyVmttLMVjY3Nx/pc8i6Hx3UTEQk11jvjC0CLgT+PJlebWaX5q7k7g+4+3x3n19XV3fUD6YWvYhIvpEE/VZgdtb1+mTekOsk/fJVQAtx6/8ld9/t7h3ACuDcYy16ODrWjYhIvpEE/evAKWbWYGYlwHXA8px1lgM3JpevAZ73OHGfAT5mZhXJB8C/Bd4endLz6TDFIiL5ig63grtnzOwW4tBOA8vcfZ2ZfQdY6e7LgQeBh82sEdhD/GGAu+81s/uIPywcWOHuT43Rc4nH0Udjde8iIh9Nhw16AHdfQdztkj3vrqzLXcCXh7ntI8RDLMeczjAlIpIvqF/G6pyxIiL5wgr6lFr0IiK5ggp6HetGRCRfUEGvrhsRkXxBBX1aO2NFRPIEFfT6ZayISL6ggl599CIi+YIK+pRBpCa9iMgggQW9um5ERHKFFfQaRy8ikieooDe16EVE8gQV9DpMsYhIvsCCXqNuRERyBRj0ha5CRGRiCSrodc5YEZF8QQW9jnUjIpIvsKBXi15EJFdgQa+dsSIiuYIKeo2jFxHJF1TQaxy9iEi+wIJeLXoRkVxhBX1KffQiIrnCCnoDd3XfiIhkCyzoDUBj6UVEsgQW9PFU3TciIgOCCnpLWvTaISsiMiCooE8dDHolvYhIv8CCPp4q6EVEBgQW9Oq6ERHJFVTQm1r0IiJ5ggr6g8MrowIXIiIygQQW9PFULXoRkQFhBX1Ko25ERHIFFfQaRy8iki+ooO/vutGxbkREBgQW9GrRi4jkCizo46n66EVEBowo6M1soZltMLNGM1s6xPJSM3ssWf6qmc3NWT7HzNrN7PZRqnu4OgEFvYhItsMGvZmlgR8Ci4B5wPVmNi9ntZuAve5+MnA/cG/O8vuAp4+93ENL6zDFIiJ5RtKiXwA0uvt77t4DPAoszllnMfBQcvkJ4FJLmtdmdhXwPrBuVCo+hFTybNSiFxEZMJKgPx7YknW9KZk35DrungFagVozmwR8Hfj2oR7AzJaY2UozW9nc3DzS2vNoZ6yISL6x3hl7N3C/u7cfaiV3f8Dd57v7/Lq6uqN+MPXRi4jkKxrBOluB2VnX65N5Q63TZGZFQBXQAnwSuMbMvgdMBSIz63L3fzjWwoeicfQiIvlGEvSvA6eYWQNxoF8HfCVnneXAjcDLwDXA8x6n7UX9K5jZ3UD7WIU8qOtGRGQohw16d8+Y2S3AM0AaWObu68zsO8BKd18OPAg8bGaNwB7iD4Nxp3H0IiL5RtKix91XACty5t2VdbkL+PJh7uPuo6jviPT30fepSS8iclBgv4zVOHoRkVyBBX08VdeNiMiAwIJeO2NFRHIFFfQ6Z6yISL6ggn6gj15BLyLSL8igV9eNiMiAwII+nkZKehGRg4IKep0zVkQkX1BBr2PdiIjkCyvoU2rRi4jkCivodZhiEZE8gQV9PFXQi4gMCCzodawbEZFcQQa9WvQiIgOCCvqBQyAUtg4RkYkkqKBXi15EJF9YQZ88G42jFxEZEFbQ65exIiJ5Agv6eKpTCYqIDAgq6E199CIieYIKeo2jFxHJF1jQx1O16EVEBgQW9NoZKyKSK6ig1zljRUTyBRX0OmesiEi+IINeXTciIgMCC/p4qq4bEZEBYQW9zjAlIpInrKBXH72ISJ7Agj6eRmrSi4gcFFTQm3bGiojkCSrotTNWRCRfYEGvY92IiOQKMujVohcRGRBU0OucsSIi+YIKerXoRUTyBRb08VTDK0VEBowo6M1soZltMLNGM1s6xPJSM3ssWf6qmc1N5l9mZm+Y2Zpk+tlRrn8QHetGRCTfYYPezNLAD4FFwDzgejObl7PaTcBedz8ZuB+4N5m/G/iiu38MuBF4eLQKH7rWeKquGxGRASNp0S8AGt39PXfvAR4FFuessxh4KLn8BHCpmZm7/9HdtyXz1wHlZlY6GoUPxcww0yEQRESyjSTojwe2ZF1vSuYNuY67Z4BWoDZnnS8Bq9y9O/cBzGyJma00s5XNzc0jrX1IKTN13YiIZBmXnbFmdiZxd87NQy139wfcfb67z6+rqzumx0qZum5ERLKNJOi3ArOzrtcn84Zcx8yKgCqgJbleDzwJ/KW7bzrWgg/H1KIXERlkJEH/OnCKmTWYWQlwHbA8Z53lxDtbAa4Bnnd3N7OpwFPAUnf//SjVfEgp9dGLiAxy2KBP+txvAZ4B3gEed/d1ZvYdM7syWe1BoNbMGoG/BfqHYN4CnAzcZWark7/po/4sssR99Ap6EZF+RSNZyd1XACty5t2VdbkL+PIQt/su8N1jrPGIpNV1IyIySFC/jIV4LL1a9CIiA4IL+lTKdJhiEZEs4QW9+uhFRAYJMOjVdSMiki24oNc4ehGRwYILeo2jFxEZLMCgN6Ko0FWIiEwcYQa9WvQiIgcFF/TxOPpCVyEiMnEEF/Rq0YuIDBZg0Gt4pYhItgCDXsMrRUSyBRf0OtaNiMhgwQV9ykzj6EVEsgQZ9BpHLyIyILigV9eNiMhgwQV9OqWdsSIi2YILevXRi4gMFmDQq+tGRCRbcEGvwxSLiAwWXNCrRS8iMliAQa9zxoqIZAsy6NWiFxEZEFzQaxy9iMhgwQW9DmomIjJYeEGf0jljRUSyhRP0+z6E577NcX3b1aIXEckSTtB3tcHv7qOhp1F99CIiWYoKXcCoqWkAYGZfE5Ep6EVE+oXToi+phMkzmZFR142ISLZwgh6g5kSm925V142ISJbggn5GZqta9CIiWYIL+qq+vWQ62gpdiYjIhBFc0AMUt23mveb2AhcjIjIxhBX0tScBMNd28Pz6XQUuRkRkYggr6KvjIZbnT9nHc+/sLHAxIiITQ1hBXzoJJh3H/MktdH2wks6X/h5WLoO+3rF5vO522Px7OLD70Ou1NkFv59jUICJyGCP6wZSZLQT+J5AG/tHd78lZXgr8DDgPaAH+zN03J8vuBG4C+oD/7O7PjFr1Q6k5kY99+BT/p/gpeD6e1fyvf0/z7MuprJ5BTUlEZXkZqZJyKCqHKAPd+2H/NujpgHQJTD8dSifHHxA1J8Lm38G7/wLzFsNpi6DlPXj9H6HxOYh6AYPZC2D+TTDrHDiwCzb+BqrnQsduePEeqKyD0z8PG56Gilr4xPVwyuegpRE2/xbmXAAV06B1C1gKdqyBD1+GM6+GUxfC7o3xkykqheLyeFpUHs9759ewcx0c93GoPx+KK2DNL6FsCpx8GVQdH983wM41UFoF006GvZuh5wBMOT5+Lr2dcMYXoXwq7N8Jf/wZTJ8Hp1wOmS7Y/mb8oTV1dvzcJh0XH1woW6Ynfk51p0EqffSvozt88Hsoq4IZZ8WHJZ0otq6K3xtzPlnoSj66+odAT4TXNYqg90D8Px8oO9wBwMwsDbwLXAY0Aa8D17v721nr/Cfg4+7+VTO7Drja3f/MzOYBvwAWALOA54BT3b1vuMebP3++r1y58uif0Vu/hI3PsLpsAU/saSBqWsVfdT7ESbaN9CF+MdtDMZ1WTik9lHlX3vJdJfVM72k6eL09PZU1065gZ/W5TO9o5IzmFVR3fnhweUSKFBEA79V9lsruXdS1vU1T7acp79lN3f53Dq7rGMbg2iIrYn/lHKra3xvR0+4sP47yzh0Hr/elSkh5BvNo4HEsjSWbvqd8BiWd+d1bUaqE7qoTKdn/IelMx7D1AXiqiL7SqURl1fFf6RRKd6wi3bWHzKRZ9Mz+N3hZNd5zAHeILE3FB8+T6uui88SFkC6maH8TRfvep6/6ZPqqG0i3fYiX15Lat5mSD38bP5eqE+ir/yReVo117yO1ewOprlYwwyfPxCfPwqfMhLJqrH0ntvsdKK6EqA9r34FPPg6bfBwG+KQZeKoY27kOnzITrzsD6+2EPZuwXW9jze9AXw+UTIaSSfj0efiJFx/cbrbnfXj1R/F2Peua+IO1pDL+NlkyKQ6ujr3wwe+gowVOuyIOkN7O+AM+XRx/aK/+OfR2wNQT4ORLYeqc+HHLq+MPkQO74w/RdAmkS+Pbde6FPZuganZ8fftbcUNk1tnxC7JrfdzImPkJKK8BHKK++MN5//b4vifNgIqaeH77TmjbGjdCOlrg/d/GjZpMFzRcBDUnweSZMHlGPC2viWtq3xX/RRnwKK6xpiFuNOzfHj9GURl07YtrgrhxkOmGrtb4uFRvPR7Pv/y78Ta0dNzA6dwL7Tvi519RC1X1kCqK/w7shk3Pxw2dGWfGz690Ckw+LnnzZiDqw6MMpIqx4jJo3hA/n2mnxs+1qy2+z+790NMef+C89D3Y+TZ85va4YVWcNAIznfF26WiJ309TZ8d17FgTf9jP/ES8/btaoWsvOFBZG2/PkknxtnFPphF4X9blKH4NPIq3WUsjtGyK6zzvxhH9z+cyszfcff6Qy0YQ9J8C7nb3y5PrdwK4+3/NWueZZJ2XzawI2AHUAUuz181eb7jHO+agH0JvX8SW5n1s27GTLfud7XvbaWtrw/q66ImMdi+jlUlkIshkMtT0bifV101PZMzMbGGb17He5jKv921m+zba0tX8vu9M9vak6OhJAoCIc20jx1sL3RTx2+jjzLFdTOEAr/npAJTSSzclAJxgO7gwtZbdXsWL0Sc4J9VIGd1s8ekYTrNPpZVKPpV6mxNtOxuiejIUUUovZdYTfyDRS4n1sjI6lc0+k6ns5+zUJmpp4zfReRTRx/mpDdRaGzW0UW7dvB3NZbrt5fzUBt6ITqHZpzLHdvFqdAbdFHNF+lVOsm20U84/ZK7iJNvGWan36fQyNng9H/gMZlkLc2wXs2w31bQz1dqT6X7e85m8HJ3JxanVnJ7aQhUH6KAUA8rp5tXodLoo5ZLUH+mhmB1ewwc+g9PtQ2baHrZ4HdOsFYD7M9fQQxGXpFZzdmoTZXRzgHIao1nspopi+phue5llLcxgL8XWR5cXs8FnU0L8TWunV3Oc7aHWWgGjhjbS5nwQTWeG7aXM4m69A17Kuz6b9dFsuiihki4mWwfnpTYy3fYNej89lrmYnUzl5vRTlNrQ3YLtXk475Rxne4Zcvt7n0OTTOcmaaLAdQ65zOH1uh2y8HKkWqljJmfRQzLm8wwx2U0R0+BseoQjjtdQ5VPs+TvORNWSyb5saotFxLHZRzTpv4BJbNar3e6S6KebN2itYcOvPjur2xxr01wAL3f0/Jtf/Aviku9+Stc7aZJ2m5Pom4JPA3cAr7v5IMv9B4Gl3f2K4xxuLoB9L7k7k8dRJPsDxg99Ms69HWeuQdT3yeLnnXB+YH99H/+PEPwjrXydZFg08jh/qvqOB+WTdPrl6cD0G1T34cSMfXCPJ/cU19C8buM90yihOG+lUCnenL4r/Inf6Iujr31hRhJtB/+2Jv9YPbNeBbZ67bd2doqiLDMV4aqBH8uBziJw+d9JRhmJ6yRRVkIp6qexpJpMqo7N4Kj7ULiuPmNK1jZ5UGQDmGdpLZ+AOFmUo6WunONNBcdRBcV8n5hHd6Qr2lJ1AHymmdzTiOJlUGeW9e0l5H51FVewqPzFu/TtUd31IaWY/fVZMee9eIiviQHENAKmol6Koh7Rn6EmX01JaT1XPToqibnaWnURNdxPTuj4AoKWsnvaiGmZ2bKAk6iRKns/+4jpaS6ZTnmljUmYP5Zk2+kjRUTSV1pIZVPbupTtdzu7SE+JvSf29Kh5RkWllUm8zkzO7qci0kSKiPT2VtuJpRJYmIk1x1EVtTxPdqQpai6ZR0dOCRRm6rYw9FQ0UFRVRm9lJF6W0ejmtXklfuow0Gc5qf5nKqJ2U9wERB1JTaE1X056eSmVmL1N6d2OeoSzleHE5b5edQ2kqYlZmK70RFPW2UdG9O647VYSliigvLSEV9dLZ0c6u4nqidCkzej6ktWQ6XUVTqMnspDs9iZ6iSZRFnWyvPIO+4kk0dL3D5M4tRD0deHcH3VZKe7qKzqIqyqMOpmZ2kSZiT8lMPqg4i/qO9UzK7OFAahIHUpNxj6jMtFJDGxXWSSYyet3IuGGWwiyFW5oIw0klU6OtqIbmknr2l0zn7BNq+YsLTjjyIOLQQT8hDmpmZkuAJQBz5swpcDVHxsxIG8AE6GuUMXLaMdx23gjWOeMY7v8TQ8y78Bjub7wNmUsFMpLXKttHZzuPZNTNVmB21vX6ZN6Q6yRdN1XEO2VHclvc/QF3n+/u8+vq6kZevYiIHNZIgv514BQzazCzEuA6YHnOOsuB/j0I1wDPe/z9ejlwnZmVmlkDcArw2uiULiIiI3HYrht3z5jZLcAzxMMrl7n7OjP7DrDS3ZcDDwIPm1kjsIf4w4BkvceBt4EM8NeHGnEjIiKj77A7Y8fbR21nrIjIRHConbFh/TJWRETyKOhFRAKnoBcRCZyCXkQkcBNuZ6yZNQMfHMNdTAMOczjJglBdR0Z1HbmJWpvqOjJHW9cJ7j7kD5EmXNAfKzNbOdye50JSXUdGdR25iVqb6joyY1GXum5ERAKnoBcRCVyIQf9AoQsYhuo6MqrryE3U2lTXkRn1uoLroxcRkcFCbNGLiEgWBb2ISOCCCXozW2hmG8ys0cyWFrCO2Wb2gpm9bWbrzOy2ZP7dZrbVzFYnf1cUqL7NZrYmqWFlMq/GzH5jZhuTafU413Ra1nZZbWZtZvY3hdhmZrbMzHYlZ03rnzfk9rHYD5L33Ftmdu441/XfzGx98thPmtnUZP5cM+vM2m4/Gau6DlHbsK+dmd2ZbLMNZnb5ONf1WFZNm81sdTJ/3LbZITJi7N5nfvC0bx/dP+LDJ28CTgRKgDeBeQWqZSZwbnJ5MvGJ1ecRn1bx9gmwrTYD03LmfQ9YmlxeCtxb4NdyB3BCIbYZ8BngXGDt4bYPcAXwNPHpxS4AXh3nuj4HFCWX782qa272egXaZkO+dsn/wptAKdCQ/N+mx6uunOX/A7hrvLfZITJizN5nobToFwCN7v6eu/cAjwKLC1GIu29391XJ5f3AO8DxhajlCCwGHkouPwRcVbhSuBTY5O7H8uvoo+buLxGfUyHbcNtnMfAzj70CTDWzmeNVl7s/6+6Z5OorxGdwG3fDbLPhLAYedfdud38faCT+/x3XuszMgGuBX4zFYx/KITJizN5noQT98cCWrOtNTIBwNbO5wDnAq8msW5KvXsvGu3skiwPPmtkbFp+rF2CGu29PLu8AZhSmNCA+aU32P99E2GbDbZ+J9L77D8Stvn4NZvZHM/t/ZnZRgWoa6rWbKNvsImCnu2/Mmjfu2ywnI8bsfRZK0E84ZjYJ+BXwN+7eBvwYOAk4G9hO/LWxEC5093OBRcBfm9lnshd6/F2xIGNuLT5V5ZXAL5NZE2WbHVTI7TMcM/sG8Rnc/jmZtR2Y4+7nAH8L/NzMpoxzWRPutctxPYMbFOO+zYbIiING+30WStCP6CTk48XMiolfwH929/8N4O473b3P3SPgp4zR19XDcfetyXQX8GRSx87+r4LJdFchaiP+8Fnl7juTGifENmP47VPw952Z/RXwBeDPk3Ag6RZpSS6/QdwPfup41nWI124ibLMi4N8Dj/XPG+9tNlRGMIbvs1CCfiQnMB8XSd/fg8A77n5f1vzsPrWrgbW5tx2H2irNbHL/ZeKdeWsZfHL3G4Ffj3dtiUGtrImwzRLDbZ/lwF8moyIuAFqzvnqPOTNbCPwdcKW7d2TNrzOzdHL5ROAU4L3xqit53OFeu+XAdWZWamYNSW2vjWdtwL8D1rt7U/+M8dxmw2UEY/k+G4+9zOPxR7xn+l3iT+JvFLCOC4m/cr0FrE7+rgAeBtYk85cDMwtQ24nEIx7eBNb1byegFvhXYCPwHFBTgNoqgRagKmveuG8z4g+a7UAvcV/oTcNtH+JRED9M3nNrgPnjXFcjcd9t//vsJ8m6X0pe39XAKuCLBdhmw752wDeSbbYBWDSedSXz/xfw1Zx1x22bHSIjxux9pkMgiIgELpSuGxERGYaCXkQkcAp6EZHAKehFRAKnoBcRCZyCXkQkcAp6EZHA/X92Upmcgwui6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wf.save('model_wf BTC.h5')\n",
    "model_wof.save('model_wof BTC.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4b521e29a846470c96e928a1c4aafac58a12234cdaa98f9ca60bc431873fee6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
